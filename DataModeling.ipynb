{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc327167-c866-4282-a044-a2a8e7e9344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415fb041-cdc1-41d6-9e1a-ffd96f1a8775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       1              0        1           0       1             0   \n",
       "1       0              0        0           0      34             1   \n",
       "2       0              0        0           0       2             1   \n",
       "3       0              0        0           0      45             0   \n",
       "4       1              0        0           0       2             1   \n",
       "\n",
       "   MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "0              0               0             1                 0  ...   \n",
       "1              0               1             0                 1  ...   \n",
       "2              0               1             1                 0  ...   \n",
       "3              0               1             0                 1  ...   \n",
       "4              0               0             0                 0  ...   \n",
       "\n",
       "   MonthlyCharges  TotalCharges  Churn  InternetService_Fiber optic  \\\n",
       "0           29.85         29.85      0                        False   \n",
       "1           56.95       1889.50      0                        False   \n",
       "2           53.85        108.15      1                        False   \n",
       "3           42.30       1840.75      0                        False   \n",
       "4           70.70        151.65      1                         True   \n",
       "\n",
       "   InternetService_No  Contract_One year  Contract_Two year  \\\n",
       "0               False              False              False   \n",
       "1               False               True              False   \n",
       "2               False              False              False   \n",
       "3               False               True              False   \n",
       "4               False              False              False   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                  False                            True   \n",
       "1                                  False                           False   \n",
       "2                                  False                           False   \n",
       "3                                  False                           False   \n",
       "4                                  False                            True   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                       False  \n",
       "1                        True  \n",
       "2                        True  \n",
       "3                       False  \n",
       "4                       False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(\"data/cleaned_data.csv\", index_col =False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b03f2c1-cd52-4212-89c7-9ee1c614a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the null values\n",
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c25cc0-1b2b-4254-aa06-2b6f5e51db9b",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20925e5-54d6-4a69-825b-6c0b40c6a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Churn')\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6675d93-4147-49cd-b167-f904ba1e3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape (7043, 23)\n",
      "y Shape (7043,)\n",
      "X_train Shape (4930, 23)\n",
      "y_train Shape (4930,)\n",
      "X_test Shape (2113, 23)\n",
      "y_test Shape (2113,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape {X.shape}\")\n",
    "print(f\"y Shape {y.shape}\")\n",
    "\n",
    "print(f\"X_train Shape {X_train.shape}\")\n",
    "print(f\"y_train Shape {y_train.shape}\")\n",
    "print(f\"X_test Shape {X_test.shape}\")\n",
    "print(f\"y_test Shape {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d0def-ddf2-49b5-b578-770e51368cc4",
   "metadata": {},
   "source": [
    "### Taking care of the imbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16b546a-2d04-456c-bf3a-123c17006845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Churn\n",
      "0    3637\n",
      "1    1293\n",
      "Name: count, dtype: int64\n",
      "The number of classes after fit Churn\n",
      "1    2260\n",
      "0    1925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "st=SMOTEENN()\n",
    "X_train_st,y_train_st = st.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes before fit {}\".format(y_train.value_counts()))\n",
    "print(\"The number of classes after fit {}\".format(y_train_st.value_counts()))\n",
    "\n",
    "# splitting the over sampling dataset again after the balanced dataset\n",
    "X_train_sap, X_test_sap, y_train_sap, y_test_sap = train_test_split(X_train_st, y_train_st, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047b7c3-0974-4a88-a882-ce464298cb86",
   "metadata": {},
   "source": [
    "#### Inference: \n",
    "* We can observe that the classes after churn is more balanced than the one before oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb3343-4a85-4c59-81ca-bf9d3568eec4",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. Random Forest Classifier\n",
    "4. Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d78fc-0ac4-4c15-ad48-5aa9fcf803bd",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a6a27b-30b2-468d-bf86-0e33853d87d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9299363057324841\n",
      "Confusion matrix :\n",
      " [[534  36]\n",
      " [ 52 634]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       570\n",
      "           1       0.95      0.92      0.94       686\n",
      "\n",
      "    accuracy                           0.93      1256\n",
      "   macro avg       0.93      0.93      0.93      1256\n",
      "weighted avg       0.93      0.93      0.93      1256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "Log_reg_sampling = LogisticRegression(C=5)\n",
    "Log_reg_sampling.fit(X_train_sap, y_train_sap)\n",
    "Log_sampling_pred = Log_reg_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(Log_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(Log_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(Log_sampling_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba8a4c-bd4d-4470-bc99-aec9819d2957",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e74d24-59bb-4427-bff6-45caa7fadd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9171974522292994\n",
      "Confusion matrix :\n",
      " [[522  40]\n",
      " [ 64 630]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       562\n",
      "           1       0.94      0.91      0.92       694\n",
      "\n",
      "    accuracy                           0.92      1256\n",
      "   macro avg       0.92      0.92      0.92      1256\n",
      "weighted avg       0.92      0.92      0.92      1256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# decisionTree Classifier\n",
    "Dt_sampling = DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=7, min_samples_leaf=15)\n",
    "Dt_sampling.fit(X_train_sap, y_train_sap)\n",
    "dt_sampling_pred = Dt_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(dt_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(dt_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(dt_sampling_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9b3a9-a1ac-4e9c-a197-ee0fc00116c9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b12285a-c336-42e0-ab67-5011cc6bbbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9267515923566879\n",
      "Confusion matrix :\n",
      " [[525  31]\n",
      " [ 61 639]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       556\n",
      "           1       0.95      0.91      0.93       700\n",
      "\n",
      "    accuracy                           0.93      1256\n",
      "   macro avg       0.92      0.93      0.93      1256\n",
      "weighted avg       0.93      0.93      0.93      1256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "Rfc_sampling = RandomForestClassifier(n_estimators=150,criterion='gini', max_depth=15, min_samples_leaf=10, min_samples_split=6)\n",
    "Rfc_sampling.fit(X_train_sap, y_train_sap)\n",
    "rfc_sampling_pred = Rfc_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(rfc_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(rfc_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(rfc_sampling_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05986b60-5234-4e5f-a4ab-8f58381f14fc",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf05e704-e39d-49c3-849e-da6e9ec70767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9347133757961783\n",
      "Confusion matrix :\n",
      " [[534  30]\n",
      " [ 52 640]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       564\n",
      "           1       0.96      0.92      0.94       692\n",
      "\n",
      "    accuracy                           0.93      1256\n",
      "   macro avg       0.93      0.94      0.93      1256\n",
      "weighted avg       0.94      0.93      0.93      1256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_sap, y_train_sap)\n",
    "pred = gbc.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "070585c1-06e5-48c7-b2e2-1ecf6e7b20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[100, 200, 300],\n",
    "             'criterion': ['friedman_mse', 'squared_error', 'mse', 'mae'],\n",
    "             'min_samples_split': [2,3,4,5,6,7,8,9,10],\n",
    "             'min_samples_leaf': [1,3,5,7,9,11,13,15],'max_leaf_nodes': [3,6,8,9,12,15,18,24],\n",
    "              'max_depth': [3,5,7,9,11,13,15,17,19],\n",
    "              'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'loss': ['deviance', 'exponential']\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df11e7-d649-4db2-90e0-ade93097d20b",
   "metadata": {},
   "source": [
    "# Optimizing Hyperparameters\n",
    "## Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c001f1c9-3980-4220-b25c-79b15a959c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=4, n_estimators=300;, score=0.962 total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=4, n_estimators=300;, score=0.951 total time=   2.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=4, n_estimators=300;, score=0.964 total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=4, n_estimators=300;, score=0.961 total time=   2.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=4, n_estimators=300;, score=0.945 total time=   2.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=11, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=11, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=11, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=11, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=11, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=13, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=13, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=13, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=13, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=13, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=10, n_estimators=100;, score=0.954 total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=10, n_estimators=100;, score=0.951 total time=   0.7s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=10, n_estimators=100;, score=0.945 total time=   0.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=10, n_estimators=100;, score=0.957 total time=   0.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=10, n_estimators=100;, score=0.933 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=3, min_samples_leaf=7, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=9, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=200;, score=0.940 total time=   1.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=200;, score=0.942 total time=   1.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=200;, score=0.928 total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=200;, score=0.949 total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=200;, score=0.920 total time=   1.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=13, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.944 total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.956 total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.945 total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.954 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.933 total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=4, n_estimators=200;, score=0.966 total time=   1.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=4, n_estimators=200;, score=0.957 total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=4, n_estimators=200;, score=0.956 total time=   1.4s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=4, n_estimators=200;, score=0.957 total time=   1.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=4, n_estimators=200;, score=0.935 total time=   1.8s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3, n_estimators=100;, score=0.961 total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3, n_estimators=100;, score=0.956 total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3, n_estimators=100;, score=0.939 total time=   0.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3, n_estimators=100;, score=0.933 total time=   0.5s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.942 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.947 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.927 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.951 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=10, n_estimators=100;, score=0.921 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.959 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.951 total time=   1.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.945 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.951 total time=   1.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.937 total time=   1.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.951 total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.949 total time=   0.7s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.937 total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.944 total time=   0.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=0.926 total time=   0.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=3, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=3, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=3, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=3, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.3, loss=deviance, max_depth=3, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=10, n_estimators=100;, score=0.966 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=10, n_estimators=100;, score=0.959 total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=10, n_estimators=100;, score=0.949 total time=   0.7s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=10, n_estimators=100;, score=0.959 total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=10, n_estimators=100;, score=0.935 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=11, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.939 total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=11, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.951 total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=11, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.942 total time=   0.7s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=11, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.942 total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=11, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.932 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=5, n_estimators=200;, score=0.956 total time=   1.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=5, n_estimators=200;, score=0.949 total time=   1.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=5, n_estimators=200;, score=0.952 total time=   1.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=5, n_estimators=200;, score=0.954 total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=5, n_estimators=200;, score=0.935 total time=   1.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.9s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=5, n_estimators=300;, score=0.949 total time=   1.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=5, n_estimators=300;, score=0.949 total time=   1.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=5, n_estimators=300;, score=0.947 total time=   1.9s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=5, n_estimators=300;, score=0.933 total time=   1.9s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=0.951 total time=   1.5s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=0.959 total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=0.939 total time=   1.4s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=0.952 total time=   1.4s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=8, n_estimators=300;, score=0.938 total time=   1.3s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.951 total time=   1.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.945 total time=   1.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.927 total time=   1.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.949 total time=   1.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.918 total time=   1.3s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=1, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=1, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=1, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=1, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=24, min_samples_leaf=1, min_samples_split=9, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=7, n_estimators=200;, score=0.957 total time=   1.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=7, n_estimators=200;, score=0.951 total time=   2.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=7, n_estimators=200;, score=0.951 total time=   1.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=7, n_estimators=200;, score=0.957 total time=   1.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=7, n_estimators=200;, score=0.932 total time=   1.4s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.957 total time=   1.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.954 total time=   1.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.951 total time=   1.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.957 total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.937 total time=   1.1s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=3, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=3, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=3, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=3, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=3, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=3, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=10, n_estimators=300;, score=0.925 total time=   1.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=10, n_estimators=300;, score=0.947 total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=10, n_estimators=300;, score=0.923 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=10, n_estimators=300;, score=0.944 total time=   1.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=10, n_estimators=300;, score=0.915 total time=   2.1s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=2, n_estimators=300;, score=nan total time=   0.1s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=11, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=5, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=5, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=5, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=5, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=5, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=0.951 total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=0.952 total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=0.939 total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=0.951 total time=   0.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=3, n_estimators=200;, score=0.923 total time=   0.7s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=3, min_samples_leaf=11, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=100;, score=0.951 total time=   1.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=100;, score=0.954 total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=100;, score=0.942 total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=100;, score=0.954 total time=   1.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=100;, score=0.932 total time=   1.1s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.959 total time=   2.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.952 total time=   1.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.932 total time=   1.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.959 total time=   1.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.945 total time=   1.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=7, n_estimators=100;, score=0.954 total time=   0.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=7, n_estimators=100;, score=0.956 total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=7, n_estimators=100;, score=0.944 total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=7, n_estimators=100;, score=0.954 total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=3, min_samples_split=7, n_estimators=100;, score=0.938 total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=18, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=18, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=18, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=18, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=18, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=0.957 total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=0.954 total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=0.940 total time=   0.7s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=0.956 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=0.937 total time=   0.8s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=9, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=9, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=9, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=9, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=9, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=7, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=7, min_samples_split=5, n_estimators=100;, score=0.940 total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=7, min_samples_split=5, n_estimators=100;, score=0.944 total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=7, min_samples_split=5, n_estimators=100;, score=0.927 total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=7, min_samples_split=5, n_estimators=100;, score=0.951 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=7, min_samples_split=5, n_estimators=100;, score=0.916 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=4, n_estimators=100;, score=0.951 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=4, n_estimators=100;, score=0.954 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=4, n_estimators=100;, score=0.935 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=4, n_estimators=100;, score=0.944 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=4, n_estimators=100;, score=0.932 total time=   0.4s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=9, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "375 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "155 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "115 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mae' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/dhruvpatel/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.95663662        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94810011        nan        nan        nan        nan        nan\n",
      " 0.93580876        nan        nan        nan 0.94639363 0.95424404\n",
      "        nan 0.9501479         nan        nan        nan        nan\n",
      " 0.93751583 0.94844258 0.94127184        nan 0.95356145 0.94093229\n",
      "        nan        nan        nan 0.94912459        nan 0.94810011\n",
      "        nan        nan        nan 0.94776057        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93785596        nan        nan 0.94946472        nan        nan\n",
      " 0.95117295        nan        nan        nan        nan        nan\n",
      "        nan 0.93068755        nan        nan        nan        nan\n",
      "        nan 0.94297716        nan        nan        nan 0.94639305\n",
      "        nan        nan        nan        nan 0.94946939        nan\n",
      " 0.94912575        nan        nan 0.94878387        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93546629 0.94298008        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;, &#x27;mse&#x27;,\n",
       "                                                      &#x27;mae&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;, &#x27;mse&#x27;,\n",
       "                                                      &#x27;mae&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error', 'mse',\n",
       "                                                      'mae'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        'loss': ['deviance', 'exponential'],\n",
       "                                        'max_depth': [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        'max_leaf_nodes': [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        'min_samples_leaf': [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_optm = RandomizedSearchCV(estimator=gbc, param_distributions=param_grid,n_iter=100, verbose=3)\n",
    "gbc_optm.fit(X_train_sap, y_train_sap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8339641e-bb17-4e6d-9b5a-499b10dac9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;, learning_rate=0.5,\n",
       "                           loss=&#x27;exponential&#x27;, max_depth=13, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=5, min_samples_split=4,\n",
       "                           n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;, learning_rate=0.5,\n",
       "                           loss=&#x27;exponential&#x27;, max_depth=13, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=5, min_samples_split=4,\n",
       "                           n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(criterion='squared_error', learning_rate=0.5,\n",
       "                           loss='exponential', max_depth=13, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=5, min_samples_split=4,\n",
       "                           n_estimators=300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_optm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342f086f-f8e4-4981-86d1-822a783e0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9506369426751592\n",
      "Confusion matrix :\n",
      " [[550  26]\n",
      " [ 36 644]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       576\n",
      "           1       0.96      0.95      0.95       680\n",
      "\n",
      "    accuracy                           0.95      1256\n",
      "   macro avg       0.95      0.95      0.95      1256\n",
      "weighted avg       0.95      0.95      0.95      1256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gbc_tunning = GradientBoostingClassifier(learning_rate=0.3, loss='exponential', max_depth=17,\n",
    "                           max_leaf_nodes=12, min_samples_leaf=3,\n",
    "                           min_samples_split=8, n_estimators=200)\n",
    "gbc_tunning.fit(X_train_sap, y_train_sap)\n",
    "pred = gbc_tunning.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db47fbca-ab30-43eb-a4d4-dada67de1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for model fitting\n",
    "def churn_prediction(algo, training_x, training_y, testing_x, testing_y, cols, cf = 'coefficients'):\n",
    "    algo.fit(training_x,training_y)\n",
    "    predictions = algo.predict(testing_x)\n",
    "    probabilities = algo.predict_proba(testing_x)[:,1]\n",
    "    \n",
    "    #coeffs\n",
    "    if cf == \"coefficients\":\n",
    "        coefficients = pd.DataFrame(algo.coef_.ravel())\n",
    "    elif cf == \"features\":\n",
    "        coefficients = pd.DataFrame(algo.feature_importances_)\n",
    "        \n",
    "    column_df = pd.DataFrame(cols)\n",
    "    coef_sumry = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print (algo)\n",
    "    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n",
    "    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n",
    "    \n",
    "    #confusion matrix\n",
    "    conf_matrix = confusion_matrix(testing_y,predictions)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(221)\n",
    "    sns.heatmap(conf_matrix, fmt = \"d\",annot=True, cmap='Blues')\n",
    "    plt.title('Confuion Matrix')\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    #roc_auc_score\n",
    "    model_roc_auc = roc_auc_score(testing_y,probabilities) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    fpr,tpr,thresholds = roc_curve(testing_y,probabilities)\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label = \"Auc : %.3f\" %model_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    sns.barplot(x = coef_sumry[\"features\"] ,y = coef_sumry[\"coefficients\"])\n",
    "    plt.title('Feature Importances')\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fca27eb-3267-4fc0-843b-5af6735a7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(learning_rate=0.3, loss='exponential', max_depth=17,\n",
      "                           max_leaf_nodes=12, min_samples_leaf=3,\n",
      "                           min_samples_split=8, n_estimators=200)\n",
      "\n",
      " Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1537\n",
      "           1       0.65      0.49      0.56       576\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.70      0.71      2113\n",
      "weighted avg       0.78      0.79      0.78      2113\n",
      "\n",
      "Accuracy   Score :  0.7889256980596309\n",
      "Area under curve :  0.8230787564158172 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "churn_prediction(gbc_tunning , X_train,y_train, X_test,  y_test, X.columns,\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6847d9ed-e4d3-401d-bfec-346854a8de16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59504132, 0.53393665, 0.5       , 0.60606061, 0.58874459,\n",
       "       0.51792829, 0.50655022, 0.59259259, 0.61864407, 0.59591837])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the training score\n",
    "train_scores = cross_val_score(gbc_tunning,X_train,y_train, cv = 10, scoring='f1')\n",
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57580488-8a5a-4083-95c3-f33847239303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5655416701632296"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36eb29-b388-41d1-8c2a-536563b21ce0",
   "metadata": {},
   "source": [
    "### Since our testing data and training F1-score is the same, we can conclude that there is no underfitting or overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e66a574-ac98-45d0-9ceb-6e34db6723d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the Model to Pickle file\n",
    "import pickle\n",
    "pickle.dump(gbc_tunning, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d38e0371-8590-4ec6-814b-770e6103390a",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "* https://github.com/satz2000/End-to-end-project---Customer-churn/tree/main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
